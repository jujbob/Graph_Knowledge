{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7d0aa927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchkge in /home/aailab/.local/lib/python3.8/site-packages (0.17.5)\n",
      "Requirement already satisfied: pandas>=1.4 in /home/aailab/.local/lib/python3.8/site-packages (from torchkge) (1.4.0)\n",
      "Requirement already satisfied: tqdm>=4.64 in /home/aailab/.local/lib/python3.8/site-packages (from torchkge) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.2.0 in /home/aailab/.local/lib/python3.8/site-packages (from torchkge) (1.10.0+cu111)\n",
      "Requirement already satisfied: numpy>=1.22 in /home/aailab/.local/lib/python3.8/site-packages (from torchkge) (1.23.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/aailab/.local/lib/python3.8/site-packages (from pandas>=1.4->torchkge) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/aailab/.local/lib/python3.8/site-packages (from pandas>=1.4->torchkge) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /home/aailab/.local/lib/python3.8/site-packages (from torch>=1.2.0->torchkge) (4.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas>=1.4->torchkge) (1.14.0)\n",
      "Requirement already satisfied: soynlp in /home/aailab/.local/lib/python3.8/site-packages (0.0.493)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/aailab/.local/lib/python3.8/site-packages (from soynlp) (1.8.1)\n",
      "Requirement already satisfied: psutil>=5.0.1 in /home/aailab/.local/lib/python3.8/site-packages (from soynlp) (5.9.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/aailab/.local/lib/python3.8/site-packages (from soynlp) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.12.1 in /home/aailab/.local/lib/python3.8/site-packages (from soynlp) (1.23.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/aailab/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->soynlp) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/aailab/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->soynlp) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchkge\n",
    "!pip install soynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "967f3113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from torchkge.models import ConvKBModel\n",
    "import pickle \n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm \n",
    "from kge_train import train_kge\n",
    "from torchkge.utils.datasets import load_fb15k\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from soynlp.hangle import levenshtein\n",
    "from soynlp.hangle import jamo_levenshtein\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "946c9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cbb6c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "805a5143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"./datasets/20220920_csv/병원_triple.csv\", encoding='cp949')\n",
    "#df[530:550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e600eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"./datasets/04 경찰서 병원 소방서/소방서_triple.csv\", encoding='cp949')\n",
    "FOLDER_NAME = \"datasets/20220920_csv/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4f71be8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)07.csv\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)06.csv\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)02.csv\n",
      "Reading the file:  ./datasets/20220920_csv/02 해운대_배수펌프(3075794).csv\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)05.csv\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation).xlsx\n",
      "읽으려는 파일의 포멧을 확인해야함, 파일명:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation).xlsx\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)04.csv\n",
      "Reading the file:  ./datasets/20220920_csv/병원_triple.csv\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)03.csv\n",
      "Reading the file:  ./datasets/20220920_csv/00 general_triple.csv\n",
      "Reading the file:  ./datasets/20220920_csv/소방서_triple.csv\n",
      "Reading the file:  ./datasets/20220920_csv/01 부산_유수지(15054723).csv\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)01.csv\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)08.csv\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)09.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1096315/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_1096315/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the file:  ./datasets/20220920_csv/경찰서_triple.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1096315/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "path_to_file_folder = HOME_DIR+FOLDER_NAME\n",
    "meta_data= [\"file_name\", \"colum_name\", \"value_list\"] #the meta-data should be extented based on EDA on the datasets\n",
    "df_full = pd.DataFrame(columns=meta_data)\n",
    "meta_data= [\"head\", \"relation\", \"tail\", \"file_name\"] #the meta-data should be extented based on EDA on the datasets\n",
    "kg_full = pd.DataFrame(columns=meta_data)\n",
    "\n",
    "for file_name in [file for file in os.listdir(path_to_file_folder)]:\n",
    "    file_name = file_name\n",
    "    a_file = HOME_DIR+FOLDER_NAME+file_name\n",
    "    print(\"Reading the file: \", a_file)\n",
    "    \n",
    "    try:\n",
    "        a_df = pd.DataFrame()\n",
    "        if \".csv\" in file_name:\n",
    "            a_df = pd.read_csv(a_file, encoding='cp949', names=meta_data, header=None)\n",
    "            a_df[\"file_name\"] = file_name\n",
    "        elif \".xlsx\" in file_name:\n",
    "            a_df = pd.read_excel(a_file, names=meta_data, header=None)\n",
    "            a_df[\"file_name\"] = file_name\n",
    "        else:\n",
    "            continue\n",
    "        kg_full = kg_full.append(a_df, ignore_index=True)\n",
    "        \n",
    "\n",
    "        file_name_list = []\n",
    "        colum_name_list = []\n",
    "        value_list = []\n",
    "        for col in a_df.columns:\n",
    "            col_name = col\n",
    "            col_values = list(a_df[col_name].values)\n",
    "            file_name_list.append(file_name)\n",
    "            colum_name_list.append(col_name)\n",
    "            value_list.append(col_values)\n",
    "\n",
    "        tmp_df = pd.DataFrame({\"file_name\": file_name_list,\n",
    "                            \"colum_name\": colum_name_list,\n",
    "                            \"value_list\": value_list})\n",
    "\n",
    "        df_full = df_full.append(tmp_df, ignore_index=True)\n",
    "        \n",
    "    except:\n",
    "        print(\"읽으려는 파일의 포멧을 확인해야함, 파일명: \", a_file,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "44285896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7633</td>\n",
       "      <td>start_time</td>\n",
       "      <td>0</td>\n",
       "      <td>ds_r_f15048634_202111221427(relation)07.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7634</td>\n",
       "      <td>start_time</td>\n",
       "      <td>0</td>\n",
       "      <td>ds_r_f15048634_202111221427(relation)07.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7635</td>\n",
       "      <td>start_time</td>\n",
       "      <td>0</td>\n",
       "      <td>ds_r_f15048634_202111221427(relation)07.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7636</td>\n",
       "      <td>start_time</td>\n",
       "      <td>0</td>\n",
       "      <td>ds_r_f15048634_202111221427(relation)07.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7637</td>\n",
       "      <td>start_time</td>\n",
       "      <td>0</td>\n",
       "      <td>ds_r_f15048634_202111221427(relation)07.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10438</th>\n",
       "      <td>광남지구대</td>\n",
       "      <td>latitude</td>\n",
       "      <td>35.14537016</td>\n",
       "      <td>경찰서_triple.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10439</th>\n",
       "      <td>망미2치안센터</td>\n",
       "      <td>latitude</td>\n",
       "      <td>35.1717912</td>\n",
       "      <td>경찰서_triple.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10440</th>\n",
       "      <td>부산사상경찰서</td>\n",
       "      <td>latitude</td>\n",
       "      <td>35.17452651</td>\n",
       "      <td>경찰서_triple.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10441</th>\n",
       "      <td>부산기장경찰서</td>\n",
       "      <td>latitude</td>\n",
       "      <td>35.32481808</td>\n",
       "      <td>경찰서_triple.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10442</th>\n",
       "      <td>장안파출소</td>\n",
       "      <td>latitude</td>\n",
       "      <td>35.32478276</td>\n",
       "      <td>경찰서_triple.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10443 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          head    relation         tail  \\\n",
       "0         7633  start_time            0   \n",
       "1         7634  start_time            0   \n",
       "2         7635  start_time            0   \n",
       "3         7636  start_time            0   \n",
       "4         7637  start_time            0   \n",
       "...        ...         ...          ...   \n",
       "10438    광남지구대    latitude  35.14537016   \n",
       "10439  망미2치안센터    latitude   35.1717912   \n",
       "10440  부산사상경찰서    latitude  35.17452651   \n",
       "10441  부산기장경찰서    latitude  35.32481808   \n",
       "10442    장안파출소    latitude  35.32478276   \n",
       "\n",
       "                                         file_name  \n",
       "0      ds_r_f15048634_202111221427(relation)07.csv  \n",
       "1      ds_r_f15048634_202111221427(relation)07.csv  \n",
       "2      ds_r_f15048634_202111221427(relation)07.csv  \n",
       "3      ds_r_f15048634_202111221427(relation)07.csv  \n",
       "4      ds_r_f15048634_202111221427(relation)07.csv  \n",
       "...                                            ...  \n",
       "10438                               경찰서_triple.csv  \n",
       "10439                               경찰서_triple.csv  \n",
       "10440                               경찰서_triple.csv  \n",
       "10441                               경찰서_triple.csv  \n",
       "10442                               경찰서_triple.csv  \n",
       "\n",
       "[10443 rows x 4 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "73abe64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    kge_n_epoch = 100\n",
    "    kge_lr = 1e-4\n",
    "    kge_batch = 64\n",
    "    kge_margin = 0.5\n",
    "    kge_conv_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5e7ee74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9c0265d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kg_full[[\"head\", \"relation\", \"tail\"]].to_csv(\"triple_kb2.csv\")\n",
    "kg_full = kg_full.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e2c2e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_emb_path = './kge_save'\n",
    "os.makedirs(kb_emb_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e56ee83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchkge.utils.datasets import load_fb15k\n",
    "#kg, kg_val, kg_test = load_fb15k()\n",
    "#\n",
    "#model_convKB = ConvKBModel(256,\n",
    "#                            3,\n",
    "#                            kg.n_ent,\n",
    "#                            kg.n_rel,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "93396906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "originally counts 10443\n",
      "\n",
      "user nunique 1250, item nunique 2457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100 | mean loss: 4.53336: 100%|██████████| 100/100 [00:43<00:00,  2.30epoch/s]\n"
     ]
    }
   ],
   "source": [
    "kg, model_convKB = train_kge(kg_full[[\"head\", \"relation\", \"tail\"]],\n",
    "                             epochs=config.kge_n_epoch, \n",
    "                                lr=config.kge_lr, \n",
    "                                batch_size=config.kge_batch,\n",
    "                                margin=config.kge_margin,\n",
    "                                conv_size=config.kge_conv_size\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7fafe10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3705, 256)\n"
     ]
    }
   ],
   "source": [
    "emb_entity_ = model_convKB.get_embeddings()[0].detach().cpu().numpy()\n",
    "emb_rel_ = model_convKB.get_embeddings()[1].detach().cpu().numpy()\n",
    "\n",
    "ent_emb_dim = len(emb_entity_[0])\n",
    "ent_vocab={}\n",
    "ent_vocab['<unk>'] = 0\n",
    "ent_vocab['<pad>'] = 1\n",
    "ent_vocab.update({word: i+2 for word, i in kg.ent2ix.items()})\n",
    "ent_ids = {i: word for word, i in ent_vocab.items()}\n",
    "\n",
    "pad_emb_npa = np.zeros((1, ent_emb_dim))   #embedding for '<pad>' token.\n",
    "unk_emb_npa = np.zeros((1, ent_emb_dim))   #embedding for '<unk>' token.\n",
    "\n",
    "ent_embs_npa = np.vstack((pad_emb_npa,unk_emb_npa,emb_entity_))\n",
    "print(ent_embs_npa.shape)\n",
    "ent_emb = torch.nn.Embedding.from_pretrained(torch.from_numpy(ent_embs_npa).float(), freeze=False)\n",
    "\n",
    "with open('ent_vocab_npa.npy','wb') as f:\n",
    "    np.save(f,ent_vocab)\n",
    "\n",
    "with open('ent_embs_npa.npy','wb') as f:\n",
    "    np.save(f,ent_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0ebffeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0152, -0.0386,  0.0253, -0.0403, -0.0233,  0.0279, -0.0197, -0.0037,\n",
      "          0.0324,  0.0075, -0.0005,  0.0227, -0.0307,  0.0316,  0.0081,  0.0264,\n",
      "          0.0059, -0.0098, -0.0427,  0.0028, -0.0144, -0.0316, -0.0042, -0.0256,\n",
      "          0.0158, -0.0216, -0.0094,  0.0280,  0.0358, -0.0215,  0.0054,  0.0019,\n",
      "         -0.0352,  0.0144, -0.0182,  0.0013,  0.0052,  0.0143, -0.0116,  0.0016,\n",
      "          0.0157, -0.0124,  0.0270, -0.0380, -0.0354, -0.0186, -0.0138,  0.0279,\n",
      "          0.0133,  0.0277, -0.0166,  0.0102,  0.0197, -0.0184,  0.0245,  0.0076,\n",
      "          0.0275,  0.0104,  0.0377, -0.0113,  0.0063,  0.0006,  0.0107, -0.0072,\n",
      "         -0.0145,  0.0313, -0.0250, -0.0399,  0.0067,  0.0254,  0.0384, -0.0303,\n",
      "          0.0307,  0.0225,  0.0064,  0.0074, -0.0239,  0.0184, -0.0222, -0.0257,\n",
      "         -0.0148, -0.0290, -0.0149,  0.0029, -0.0034, -0.0225,  0.0123,  0.0148,\n",
      "          0.0065,  0.0193,  0.0393,  0.0054,  0.0181,  0.0266,  0.0288, -0.0172,\n",
      "          0.0259,  0.0305,  0.0055,  0.0243,  0.0262,  0.0226, -0.0001,  0.0395,\n",
      "          0.0184,  0.0093,  0.0013, -0.0050,  0.0319, -0.0292, -0.0163,  0.0126,\n",
      "          0.0020, -0.0149,  0.0119,  0.0003, -0.0346, -0.0084,  0.0286, -0.0078,\n",
      "          0.0168,  0.0284,  0.0109,  0.0020,  0.0318,  0.0044,  0.0059, -0.0296,\n",
      "          0.0285, -0.0056,  0.0236, -0.0025,  0.0329,  0.0089, -0.0347,  0.0218,\n",
      "         -0.0216,  0.0014, -0.0123,  0.0200,  0.0295, -0.0016,  0.0111, -0.0321,\n",
      "         -0.0206,  0.0210,  0.0091, -0.0263,  0.0266, -0.0034,  0.0280, -0.0305,\n",
      "         -0.0273,  0.0148,  0.0248,  0.0219,  0.0278,  0.0091,  0.0245,  0.0318,\n",
      "         -0.0290, -0.0025, -0.0318,  0.0099,  0.0233,  0.0311,  0.0293, -0.0111,\n",
      "          0.0014,  0.0092, -0.0304, -0.0070, -0.0110, -0.0213, -0.0360, -0.0371,\n",
      "         -0.0237, -0.0221,  0.0047,  0.0324, -0.0188, -0.0084,  0.0059,  0.0033,\n",
      "         -0.0108,  0.0031,  0.0081,  0.0340, -0.0021, -0.0049,  0.0123,  0.0406,\n",
      "         -0.0062, -0.0242, -0.0041, -0.0076, -0.0195,  0.0189,  0.0235, -0.0113,\n",
      "         -0.0150, -0.0009, -0.0336, -0.0263,  0.0059,  0.0280, -0.0214,  0.0124,\n",
      "         -0.0027,  0.0351,  0.0058, -0.0043, -0.0027, -0.0217, -0.0024, -0.0240,\n",
      "          0.0311,  0.0110, -0.0016, -0.0323,  0.0046, -0.0100, -0.0256, -0.0110,\n",
      "          0.0194,  0.0349,  0.0196,  0.0034, -0.0071, -0.0045,  0.0040, -0.0093,\n",
      "          0.0293, -0.0242,  0.0245,  0.0166,  0.0118,  0.0233, -0.0229,  0.0300,\n",
      "         -0.0300, -0.0256,  0.0024, -0.0172, -0.0252,  0.0418,  0.0149, -0.0093,\n",
      "          0.0060, -0.0184,  0.0282,  0.0050,  0.0282, -0.0269,  0.0277, -0.0051],\n",
      "        [-0.0155, -0.0125, -0.0137,  0.0385,  0.0045,  0.0116,  0.0308, -0.0091,\n",
      "         -0.0086,  0.0224, -0.0139, -0.0034,  0.0069,  0.0124, -0.0166, -0.0114,\n",
      "         -0.0200,  0.0415, -0.0078, -0.0119,  0.0257,  0.0158,  0.0316,  0.0304,\n",
      "          0.0250,  0.0088,  0.0175,  0.0139, -0.0448, -0.0191,  0.0216, -0.0317,\n",
      "          0.0028,  0.0153,  0.0024,  0.0016,  0.0011, -0.0171, -0.0166, -0.0261,\n",
      "          0.0030, -0.0093, -0.0141,  0.0047, -0.0202, -0.0422,  0.0079, -0.0369,\n",
      "          0.0201,  0.0276, -0.0192,  0.0453,  0.0293, -0.0069, -0.0086,  0.0153,\n",
      "         -0.0097,  0.0218, -0.0187,  0.0034, -0.0433, -0.0023,  0.0159,  0.0247,\n",
      "         -0.0152,  0.0266, -0.0356, -0.0104,  0.0380, -0.0005, -0.0219, -0.0110,\n",
      "         -0.0337,  0.0098, -0.0224,  0.0165, -0.0295,  0.0106, -0.0032, -0.0324,\n",
      "          0.0350, -0.0119,  0.0065,  0.0097,  0.0096, -0.0292,  0.0178, -0.0143,\n",
      "         -0.0030,  0.0185,  0.0274, -0.0082, -0.0229,  0.0098, -0.0166, -0.0247,\n",
      "          0.0102,  0.0168,  0.0318, -0.0131, -0.0074,  0.0399, -0.0234,  0.0295,\n",
      "         -0.0239, -0.0144,  0.0326, -0.0003,  0.0167,  0.0230,  0.0029,  0.0170,\n",
      "         -0.0020, -0.0127,  0.0093, -0.0467,  0.0215, -0.0340, -0.0140, -0.0178,\n",
      "         -0.0010, -0.0121, -0.0405, -0.0046, -0.0179, -0.0326, -0.0201,  0.0029,\n",
      "         -0.0071,  0.0004,  0.0309,  0.0050,  0.0304, -0.0095,  0.0243, -0.0223,\n",
      "          0.0222, -0.0283,  0.0198,  0.0430, -0.0230,  0.0444,  0.0248, -0.0045,\n",
      "          0.0095,  0.0293,  0.0370,  0.0162, -0.0363,  0.0183, -0.0078,  0.0038,\n",
      "          0.0184,  0.0008, -0.0411,  0.0219,  0.0107, -0.0376,  0.0350, -0.0133,\n",
      "         -0.0054,  0.0075, -0.0260,  0.0066, -0.0087,  0.0178, -0.0360, -0.0231,\n",
      "          0.0215, -0.0069,  0.0305,  0.0245, -0.0078, -0.0241,  0.0145,  0.0319,\n",
      "          0.0337, -0.0063, -0.0082, -0.0195, -0.0396,  0.0073, -0.0102,  0.0150,\n",
      "         -0.0259,  0.0031, -0.0267,  0.0087,  0.0139, -0.0385, -0.0076, -0.0237,\n",
      "          0.0118,  0.0412,  0.0114,  0.0249, -0.0296, -0.0318, -0.0120, -0.0140,\n",
      "          0.0100, -0.0191,  0.0395, -0.0003, -0.0316,  0.0198, -0.0273, -0.0307,\n",
      "         -0.0390, -0.0053, -0.0433,  0.0163,  0.0129,  0.0234, -0.0035,  0.0230,\n",
      "          0.0405,  0.0190,  0.0095, -0.0221, -0.0276, -0.0238,  0.0243,  0.0034,\n",
      "         -0.0049, -0.0146, -0.0157,  0.0123,  0.0435,  0.0036, -0.0306,  0.0022,\n",
      "          0.0058,  0.0320, -0.0136,  0.0092, -0.0226,  0.0196,  0.0310,  0.0299,\n",
      "          0.0037, -0.0102, -0.0381, -0.0289, -0.0312, -0.0003,  0.0276,  0.0191,\n",
      "          0.0383,  0.0023, -0.0266,  0.0049,  0.0241, -0.0204, -0.0086,  0.0190]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[-0.0985,  0.1042, -0.1144,  0.0858,  0.0852,  0.0790, -0.0673,  0.1121,\n",
      "         -0.0677, -0.1262, -0.1219,  0.1085,  0.0821, -0.0613,  0.0812,  0.0851,\n",
      "         -0.0965,  0.1209,  0.1143, -0.1055,  0.0540,  0.0721,  0.0589,  0.0704,\n",
      "         -0.1099,  0.0856,  0.1011,  0.0631, -0.0668, -0.0625, -0.1041, -0.0949,\n",
      "          0.0655,  0.0728, -0.0645,  0.1006, -0.0973,  0.0746,  0.0947, -0.0785,\n",
      "         -0.0666, -0.0785, -0.0903,  0.0552,  0.0750, -0.0648, -0.1067,  0.0910,\n",
      "          0.0849,  0.1210,  0.0825,  0.0967,  0.1104, -0.0577, -0.0965,  0.0933,\n",
      "          0.0691,  0.1192, -0.1291,  0.1244, -0.1007, -0.0825, -0.0981,  0.0878,\n",
      "          0.0756, -0.1002, -0.0848,  0.0634,  0.0810, -0.0657, -0.1076, -0.0914,\n",
      "         -0.1111,  0.1207,  0.0735, -0.1079,  0.1275, -0.0904, -0.1224, -0.1216,\n",
      "          0.1199,  0.0920,  0.0918, -0.0632,  0.1070, -0.0624,  0.0842, -0.1128,\n",
      "          0.0844, -0.0753, -0.1088, -0.0900,  0.0934,  0.0907,  0.0476, -0.1253,\n",
      "         -0.0753,  0.0660, -0.1279, -0.1154,  0.1047,  0.0682,  0.0849, -0.0957,\n",
      "          0.0521, -0.0573,  0.0780,  0.1086, -0.1279, -0.1076,  0.0728,  0.0647,\n",
      "          0.0514,  0.0598,  0.0827, -0.0723,  0.0585, -0.0797,  0.1012,  0.1040,\n",
      "          0.1214, -0.1071, -0.0583, -0.0714,  0.0741, -0.0710, -0.0961,  0.0843,\n",
      "         -0.1142, -0.1054,  0.0685,  0.1119, -0.0745, -0.1157,  0.1060, -0.1246,\n",
      "          0.0897,  0.0539, -0.0773,  0.0874, -0.0943,  0.1130, -0.0776,  0.0857,\n",
      "         -0.1153,  0.0970,  0.0707,  0.0789, -0.1111,  0.0951,  0.0779,  0.0525,\n",
      "         -0.0812, -0.0903, -0.0686, -0.1164, -0.0998, -0.0606,  0.1022, -0.0865,\n",
      "          0.0730, -0.0737,  0.1007, -0.0625, -0.0789, -0.0733, -0.0694,  0.0940,\n",
      "          0.0771, -0.0869, -0.0658,  0.1140, -0.1026, -0.0866,  0.0544,  0.0924,\n",
      "          0.0845,  0.0809, -0.0454, -0.1079, -0.0649,  0.0558, -0.1068,  0.1140,\n",
      "         -0.0952, -0.0651,  0.0585, -0.0805,  0.0643, -0.0664,  0.0662, -0.0775,\n",
      "         -0.0939,  0.0761,  0.0776,  0.1255, -0.1106,  0.1228, -0.0744, -0.1132,\n",
      "         -0.0794, -0.0946,  0.0937,  0.1004, -0.1097, -0.1171, -0.0983, -0.0964,\n",
      "         -0.1088, -0.1131, -0.0917, -0.1064,  0.0628, -0.0927,  0.1098, -0.0863,\n",
      "          0.1081, -0.0570, -0.0942,  0.0899,  0.1166,  0.0916, -0.0870, -0.0604,\n",
      "         -0.0648, -0.0805,  0.0922, -0.1195,  0.1043,  0.0543,  0.0938, -0.0867,\n",
      "         -0.0813,  0.0718,  0.1051,  0.0828,  0.0917,  0.1175,  0.1053,  0.0765,\n",
      "          0.0583,  0.0753, -0.1119, -0.0819, -0.0847, -0.0954,  0.0848,  0.0755,\n",
      "          0.0936, -0.0836, -0.0651, -0.0530,  0.0997, -0.0956, -0.0708, -0.0635]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(ent_emb(torch.LongTensor([10, 15]))) \n",
    "ids = ent_vocab[\"부곡지구대\"]\n",
    "print(ent_emb(torch.LongTensor([ids])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "58a184b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3018, 3241, 2982, 2905, 2997, 2906, 3689, 2928, 3374, 3318, 3412, 3279,\n",
       "        3311, 3152, 2822, 3306, 2823, 3252, 2880,  535, 3463, 3307, 3377, 2995,\n",
       "        2887, 3314, 3281, 3703, 3438, 3200, 3563, 3148, 3302, 2611, 3357, 2864,\n",
       "        2923, 3633, 3565, 2865, 2006, 3174, 3151, 2978, 3171, 3215, 3217, 3160,\n",
       "        3286, 3285, 3634, 2608, 3327, 3415, 3247, 3439, 3253, 3243, 3263, 2930,\n",
       "        2337, 3414, 3159, 2927, 2924, 2860, 3150, 3129, 2979, 3016, 3156, 2993,\n",
       "        3250, 2888, 2970, 3321, 2862, 3186, 1821, 2980, 3017, 2852, 3019, 3587,\n",
       "         976, 3328, 3661, 3283, 3251, 3185, 3163, 3157, 3304, 2652, 2839, 3242,\n",
       "        3701, 3165, 3657, 2821])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_name=\"부곡지구대\"\n",
    "e1_ids = ent_vocab[ent_name]\n",
    "e1_torch = ent_emb(torch.LongTensor([e1_ids]))\n",
    "e2_ids = np.arange(0, len(ent_vocab))\n",
    "e2_torch = ent_emb(torch.LongTensor([e2_ids])).squeeze()\n",
    "similarity = cosine_similarity(e1_torch, e2_torch)\n",
    "s_value, s_ids = torch.topk(similarity, 100)\n",
    "s_ids = s_ids.squeeze()\n",
    "s_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "95718627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3018)\n",
      "부곡지구대\n",
      "tensor(3241)\n",
      "서면지구대\n",
      "tensor(2982)\n",
      "명장2동치안센터\n",
      "tensor(2905)\n",
      "남항해양파출소\n",
      "tensor(2997)\n",
      "반여3치안센터\n",
      "tensor(2906)\n",
      "내성지구대\n",
      "tensor(3689)\n",
      "행복한외과병원\n",
      "tensor(2928)\n",
      "대연치안센터\n",
      "tensor(3374)\n",
      "자성대파출소\n",
      "tensor(3318)\n",
      "용당119안전센터\n",
      "tensor(3412)\n",
      "좋은삼선병원\n",
      "tensor(3279)\n",
      "신호파출소\n",
      "tensor(3311)\n",
      "온천119안전센터\n",
      "tensor(3152)\n",
      "부산대학교병원\n",
      "tensor(2822)\n",
      "가덕도파출소\n",
      "tensor(3306)\n",
      "영선2치안센터\n",
      "tensor(2823)\n",
      "가야119안전센터\n",
      "tensor(3252)\n",
      "센텀119안전센터\n",
      "tensor(2880)\n",
      "금정소방서\n",
      "tensor(535)\n",
      "129.0759208\n",
      "tensor(3463)\n",
      "지사119안전센터\n",
      "tensor(3307)\n",
      "영선지구대\n",
      "tensor(3377)\n",
      "장안파출소\n",
      "tensor(2995)\n",
      "반여2\n",
      "tensor(2887)\n",
      "기장병원\n",
      "tensor(3314)\n",
      "왈레스기념침례병원\n",
      "tensor(3281)\n",
      "아미파출소\n",
      "tensor(3703)\n",
      "효성시티병원\n",
      "tensor(3438)\n",
      "중앙119안전센터\n",
      "tensor(3200)\n",
      "사직119안전센터\n",
      "tensor(3563)\n",
      "창선119안전센터\n",
      "tensor(3148)\n",
      "부산광역시의료원\n",
      "tensor(3302)\n",
      "영도병원\n",
      "tensor(2611)\n",
      "8470\n",
      "tensor(3357)\n",
      "우암파출소\n",
      "tensor(2864)\n",
      "구포부민병원\n",
      "tensor(2923)\n",
      "당감1치안센터\n",
      "tensor(3633)\n",
      "팔송파출소\n",
      "tensor(3565)\n",
      "청맥병원\n",
      "tensor(2865)\n",
      "구포성심병원\n",
      "tensor(2006)\n",
      "7902\n",
      "tensor(3174)\n",
      "부산진경찰서\n",
      "tensor(3151)\n",
      "부산남부경찰서\n",
      "tensor(2978)\n",
      "망미119안전센터\n",
      "tensor(3171)\n",
      "부산지방경찰청경찰특공대\n",
      "tensor(3215)\n",
      "산성산악119안전센터\n",
      "tensor(3217)\n",
      "삼육부산병원\n",
      "tensor(3160)\n",
      "부산북부소방서\n",
      "tensor(3286)\n",
      "연산8치안센터\n",
      "tensor(3285)\n",
      "연산119안전센터\n",
      "tensor(3634)\n",
      "패밀리병원\n",
      "tensor(2608)\n",
      "8467\n",
      "tensor(3327)\n",
      "우리병원\n",
      "tensor(3415)\n",
      "주례자연병원\n",
      "tensor(3247)\n",
      "성신항운외과\n",
      "tensor(3439)\n",
      "중앙U병원\n",
      "tensor(3253)\n",
      "송도지구대\n",
      "tensor(3243)\n",
      "서울아동병원\n",
      "tensor(3263)\n",
      "수성지구대\n",
      "tensor(2930)\n",
      "대한병원\n",
      "tensor(2337)\n",
      "8204\n",
      "tensor(3414)\n",
      "주례119안전센터\n",
      "tensor(3159)\n",
      "부산북부경찰서\n",
      "tensor(2927)\n",
      "대동병원\n",
      "tensor(2924)\n",
      "당리치안센터\n",
      "tensor(2860)\n",
      "괴정3동치안센터\n",
      "tensor(3150)\n",
      "부산기장경찰서\n",
      "tensor(3129)\n",
      "부산고려병원\n",
      "tensor(2979)\n",
      "망미2치안센터\n",
      "tensor(3016)\n",
      "봉래치안센터\n",
      "tensor(3156)\n",
      "부산백병원\n",
      "tensor(2993)\n",
      "반송파출소\n",
      "tensor(3250)\n",
      "세웅병원\n",
      "tensor(2888)\n",
      "기장소방서\n",
      "tensor(2970)\n",
      "동의병원\n",
      "tensor(3321)\n",
      "우2동\n",
      "tensor(2862)\n",
      "구덕지구대\n",
      "tensor(3186)\n",
      "부산힘찬병원\n",
      "tensor(1821)\n",
      "7722\n",
      "tensor(2980)\n",
      "메드윌병원\n",
      "tensor(3017)\n",
      "봉생병원\n",
      "tensor(2852)\n",
      "공항파출소\n",
      "tensor(3019)\n",
      "부민병원\n",
      "tensor(3587)\n",
      "태종대요양병원\n",
      "tensor(976)\n",
      "21세기라파병원\n",
      "tensor(3328)\n",
      "우리원병원\n",
      "tensor(3661)\n",
      "해동병원\n",
      "tensor(3283)\n",
      "엘리움병원\n",
      "tensor(3251)\n",
      "세흥병원\n",
      "tensor(3185)\n",
      "부산진소방서\n",
      "tensor(3163)\n",
      "부산성모병원\n",
      "tensor(3157)\n",
      "부산보훈병원\n",
      "tensor(3304)\n",
      "영동병원\n",
      "tensor(2652)\n",
      "8510\n",
      "tensor(2839)\n",
      "강서소방서\n",
      "tensor(3242)\n",
      "서부산센텀병원\n",
      "tensor(3701)\n",
      "화명일신기독병원\n",
      "tensor(3165)\n",
      "부산센텀병원\n",
      "tensor(3657)\n",
      "한빛병원\n",
      "tensor(2821)\n",
      "가덕도보건지소\n"
     ]
    }
   ],
   "source": [
    "for idx in s_ids:\n",
    "    print(idx)\n",
    "    print(ent_ids[int(idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "582e86af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_example_on_TransE(kg, ent_name=\"부곡지구대\"):\n",
    "    e1 = emb_entity_[kg.ent2ix[ent_name]]\n",
    "    r1 = emb_entity_[kg.rel2ix['koad:roadNameCode']]\n",
    "    e2 = emb_entity_[kg.head_idx]\n",
    "    similarity = cosine_similarity(torch.Tensor([e1]), torch.Tensor(e2))\n",
    "    s_value, s_ids = torch.topk(similarity, 10)\n",
    "    for idx in s_ids:\n",
    "        print(int(idx))\n",
    "        print(kg.head_idx[int(idx)])\n",
    "        print(kg.ix2ent[int(kg.head_idx[int(idx)])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78d1e6b",
   "metadata": {},
   "source": [
    "## text to KB entity module\n",
    " - input: text (entity name)\n",
    " - output: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d5c67cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDiveEmb(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, out_dim):\n",
    "        super(KLDiveEmb, self).__init__()\n",
    "\n",
    "        self.bert = transformers.XLMRobertaModel.from_pretrained('xlm-roberta-base')\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.drop_out = nn.Dropout(0.33)\n",
    "        self.fc1 = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, idx, mask):\n",
    "    \n",
    "        x = self.bert(idx, mask) \n",
    "        x = x.pooler_output\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.drop_out(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        return F.softmax(x, dim=1), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "80e38e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLEDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenizer, data, max_token):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token = max_token \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        e_name = self.data['e_name'][index] #Entity Name\n",
    "        e_emb = self.data['e_emb'][index]  #KB embedding\n",
    "            \n",
    "        tokenized = self.tokenizer.encode_plus(\"\".join(e_name),\n",
    "                                                None,\n",
    "                                                add_special_tokens=True,\n",
    "                                                max_length = self.max_token,\n",
    "                                                padding='max_length',\n",
    "                                                truncation=True,\n",
    "                                              )\n",
    "        \n",
    "        ids = tokenized['input_ids']\n",
    "        mask = tokenized['attention_mask']\n",
    "\n",
    "        return {'e_ids': torch.tensor(ids, dtype=torch.long), \n",
    "                'e_mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'target': torch.tensor(e_emb)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b4a33ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = KLDiveEmb(768, 512, 256).to(DEVICE)\n",
    "criterion = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005)\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1e5d6e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "k,i,v = [],[],[]\n",
    "for ent, idx in ent_vocab.items():\n",
    "    ent_name=ent\n",
    "    e1_ids = ent_vocab[ent_name]\n",
    "    e1_torch = ent_emb(torch.LongTensor([e1_ids]))\n",
    "    k.append(ent)\n",
    "    i.append(idx)\n",
    "    v.append(e1_torch.squeeze().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "07306a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['e_name','e_idx', 'e_emb'])\n",
    "df[\"e_name\"] = k\n",
    "df[\"e_idx\"] = i\n",
    "df[\"e_emb\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4a1236d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(df, test_size=0.2)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "89df0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KLEDataset(tokenizer, train_df, max_token=20)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=4, shuffle=True, pin_memory=True)\n",
    "valid_dataset = KLEDataset(tokenizer, valid_df, max_token=20) \n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size , num_workers=4, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "55d531ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    batch_loss = []\n",
    "    for idx, batch in tqdm(enumerate(train_loader), total=len(train_loader), leave=False): #학습 데이터를 batch size만큼씩 읽어옴\n",
    "        optimizer.zero_grad()\n",
    "        e_ids = batch['e_ids'].to(DEVICE) #entity_name\n",
    "        e_bert_mask = batch['e_mask'].to(DEVICE) \n",
    "        \n",
    "        logits, _ = model(e_ids, e_bert_mask) \n",
    "                \n",
    "        target = batch['target'].to(DEVICE) #KB embedding\n",
    "        target = F.softmax(target, dim=1)\n",
    "        target.requires_grad = False\n",
    "        loss = criterion(logits.log(), target)\n",
    "\n",
    "        batch_loss.append(float(loss.item()))\n",
    "        loss.backward(loss)\n",
    "        optimizer.step()\n",
    "        \n",
    "    return sum(batch_loss) / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9c97426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fn(model, valid_loader, criterion):\n",
    "    model.eval()\n",
    "    batch_loss = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in tqdm(enumerate(valid_loader), total=len(valid_loader), leave=False): #학습 데이터를 batch size만큼씩 읽어옴\n",
    "            optimizer.zero_grad()\n",
    "            e_ids = batch['e_ids'].to(DEVICE) #entity_name\n",
    "            e_bert_mask = batch['e_mask'].to(DEVICE) \n",
    "            \n",
    "            logits, _ = model(e_ids, e_bert_mask) \n",
    "                    \n",
    "            target = batch['target'].to(DEVICE) #KB embedding\n",
    "            target = F.softmax(target, dim=1)\n",
    "            loss = criterion(logits.log(), target)\n",
    "\n",
    "            batch_loss.append(float(loss.item()))\n",
    "        \n",
    "    return sum(batch_loss) / len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1084ae79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0011047788380466877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007820807885319153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007500254841362859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007338873284096096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007221453223734143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007163975003888791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007074016104254158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007064365955228184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006956510775861271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006915453234390217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006862981554536902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006776236956245564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006765307520486493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006727738426057028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006702294885279968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006655354369828042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006651560753643354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006606326440963498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006595383660788548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006582639254431458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000656134471237818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006614516828546024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006549627733159255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006509550916466941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006532270691674599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006477138537794669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006479476993418041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006465415291963739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006445920815631906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006399445181236939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000640076214814202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006294360952798595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006196999066618291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006054202429058546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005885190336638071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005717270975397464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005578720859162747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005373317696292826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005222096267661595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004973283868550541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004856651165879312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004665445297352098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004552792475380479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00044451811737281847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00043204425526981025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00042256106191532726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004142943938124053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00041264049743520135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004093153488901543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00039462706425841504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_epoch_loss = []\n",
    "test_epoch_loss = []\n",
    "for epoch in range(50):\n",
    "    train_avg_loss = train_fn(model, train_loader, optimizer, criterion)\n",
    "    train_epoch_loss.append(train_avg_loss)\n",
    "    print(train_avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "977ecb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00031440665043191984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "valid_avg_loss = valid_fn(model, valid_loader, criterion)\n",
    "print(valid_avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5abddef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, keyword=\"춘천\"):\n",
    "\n",
    "    e_name = keyword\n",
    "    tokenized = tokenizer.encode_plus(\"\".join(e_name),\n",
    "                                        None,\n",
    "                                        add_special_tokens=True,\n",
    "                                        max_length = 20,\n",
    "                                        padding='max_length',\n",
    "                                        truncation=True,\n",
    "                                        )\n",
    "\n",
    "    ids = tokenized['input_ids']\n",
    "    mask = tokenized['attention_mask']\n",
    "\n",
    "    batch = {'e_ids': torch.tensor(ids, dtype=torch.long), \n",
    "             'e_mask': torch.tensor(mask, dtype=torch.long)}\n",
    "\n",
    "    e_ids = batch['e_ids'].to(DEVICE).unsqueeze(0) #entity_name\n",
    "    e_bert_mask = batch['e_mask'].to(DEVICE).unsqueeze(0) \n",
    "    logits, word_emb = model(e_ids, e_bert_mask)\n",
    "    e1_torch = word_emb.cpu()\n",
    "    e2_ids = np.arange(0, len(ent_vocab))\n",
    "    e2_torch = ent_emb(torch.LongTensor([e2_ids])).squeeze()\n",
    "    similarity = cosine_similarity(e1_torch, e2_torch)\n",
    "    s_value, s_ids = torch.topk(similarity, 10)\n",
    "    s_ids = s_ids.squeeze()\n",
    "    s_ids\n",
    "\n",
    "    return s_ids.detach().numpy(), s_value.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e226f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_ex_matching(df, query = \"<unk>\"):\n",
    "    keyword = query\n",
    "    exist_boolean = (df[\"e_name\"] == keyword).any()\n",
    "    ex_matching = 0 #기본적으로 \"<unk>\"로 해둠\n",
    "    if exist_boolean: \n",
    "        ex_matching = int(df[df[\"e_name\"] == keyword]['e_idx']) \n",
    "    else: \n",
    "        ex_matching = 0\n",
    "\n",
    "    return ex_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6c3989fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_sim(df, query):\n",
    "    #idx = df[\"e_name\"].apply(lambda x: levenshtein(x, query)).idxmin()\n",
    "    idx = df[\"e_name\"].apply(lambda x: jamo_levenshtein(x, query)).idxmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f0e44c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_ent_sim(ent_vocab, ent_emb, query, topN=5):\n",
    "    ent_name=query\n",
    "    e1_ids = ent_vocab[ent_name]\n",
    "    e1_torch = ent_emb(torch.LongTensor([e1_ids]))\n",
    "    e2_ids = np.arange(0, len(ent_vocab))\n",
    "    e2_torch = ent_emb(torch.LongTensor([e2_ids])).squeeze()\n",
    "    similarity = cosine_similarity(e1_torch, e2_torch)\n",
    "    s_value, s_ids = torch.topk(similarity, topN)\n",
    "    s_ids = s_ids.squeeze()\n",
    "    return s_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "65f3defd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Graph similarity 유사도 결과 ----------\n",
      "유사 Entity:  tensor(3158)   부산본병원\n",
      "유사 Entity:  tensor(3241)   서면지구대\n",
      "유사 Entity:  tensor(2822)   가덕도파출소\n",
      "유사 Entity:  tensor(2928)   대연치안센터\n",
      "유사 Entity:  tensor(3148)   부산광역시의료원\n",
      "---------- Graph similarity 유사도 끝 ----------\n",
      "\n",
      "\n",
      "---------- BERT-Entity 유사도 결과 시작 ----------\n",
      "[[2569, '8428']]\n",
      "[[3241, '서면지구대']]\n",
      "[[535, '129.0759208']]\n",
      "[[2286, '8156']]\n",
      "[[1804, '7705']]\n",
      "[[2996, '반여23파출소']]\n",
      "[[2680, '8538']]\n",
      "[[3215, '산성산악119안전센터']]\n",
      "[[3691, '허브휴병원']]\n",
      "[[2964, '동래병원']]\n",
      "---------- BERT-Entity 유사도 결과 끝 ----------\n"
     ]
    }
   ],
   "source": [
    "query = \"부산진병원\"\n",
    "\n",
    "#EXmatching 결과\n",
    "ex_ids = search_ex_matching(df, query)\n",
    "ex_sim_query = df[df['e_idx'] == int(ex_ids)][\"e_name\"].iloc[0]\n",
    "\n",
    "#Levenshtein 유사도 결과\n",
    "lev_ids = levenshtein_sim(df, query)\n",
    "lev_sim_query = df[df['e_idx'] == int(lev_ids)][\"e_name\"].iloc[0]\n",
    "\n",
    "print(\"---------- Graph similarity 유사도 결과 ----------\")\n",
    "if ex_ids != 0:\n",
    "    graph_ids = graph_ent_sim(ent_vocab, ent_emb, ex_sim_query)\n",
    "else:\n",
    "    graph_ids = graph_ent_sim(ent_vocab, ent_emb, lev_sim_query)\n",
    "\n",
    "\n",
    "for idx in graph_ids:\n",
    "    print(\"유사 Entity: \", idx, \" \", df.iloc[int(idx)][\"e_name\"])\n",
    "print(\"---------- Graph similarity 유사도 끝 ----------\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#BERT-Entity 유사도 결과\n",
    "print(\"---------- BERT-Entity 유사도 결과 시작 ----------\")\n",
    "s_ids, s_score = prediction(model, query)\n",
    "total_ids = s_ids #np.concatenate([np.array([ex_ids]), np.array([lev_ids]), s_ids]) \n",
    "for seq_num, idx in enumerate(total_ids):\n",
    "    print(df[df['e_idx'] == int(idx)][[\"e_idx\",\"e_name\"]].values.tolist())\n",
    "print(\"---------- BERT-Entity 유사도 결과 끝 ----------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7145a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_sim_ent = df[df['e_idx'] == int(lev_ids)][\"e_name\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f09d732f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3158"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['e_idx'] == int(lev_ids)][\"e_idx\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c505d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbj_possible_rel = kg_full[kg_full[\"head\"]==most_sim_ent][[\"relation\", \"tail\", \"file_name\"]]\n",
    "obj_possible_rel = kg_full[kg_full[\"tail\"]==most_sim_ent][[\"head\", \"relation\", \"file_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5ae7286a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5099</th>\n",
       "      <td>is_a</td>\n",
       "      <td>koad:hospital</td>\n",
       "      <td>병원_triple.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5207</th>\n",
       "      <td>kord:RoadNameAddress</td>\n",
       "      <td>부산 사하구 승학로 8</td>\n",
       "      <td>병원_triple.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>contact:phone</td>\n",
       "      <td>1599-8275</td>\n",
       "      <td>병원_triple.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>koad:roadNameCode</td>\n",
       "      <td>2638055000</td>\n",
       "      <td>병원_triple.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531</th>\n",
       "      <td>longitude</td>\n",
       "      <td>128.9698294</td>\n",
       "      <td>병원_triple.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5639</th>\n",
       "      <td>latitude</td>\n",
       "      <td>35.10628188</td>\n",
       "      <td>병원_triple.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   relation           tail      file_name\n",
       "5099                   is_a  koad:hospital  병원_triple.csv\n",
       "5207   kord:RoadNameAddress   부산 사하구 승학로 8  병원_triple.csv\n",
       "5315          contact:phone      1599-8275  병원_triple.csv\n",
       "5423      koad:roadNameCode     2638055000  병원_triple.csv\n",
       "5531              longitude    128.9698294  병원_triple.csv\n",
       "5639               latitude    35.10628188  병원_triple.csv"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbj_possible_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "15cbd7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [head, relation, file_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_possible_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8a73ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
