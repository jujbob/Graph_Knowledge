{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0aa927",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchkge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "967f3113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from torchkge.models import ConvKBModel\n",
    "import pickle \n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm \n",
    "from kge_train import train_kge\n",
    "from torchkge.utils.datasets import load_fb15k\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "946c9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cbb6c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "805a5143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"./datasets/20220920_csv/병원_triple.csv\", encoding='cp949')\n",
    "#df[530:550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e600eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"./datasets/04 경찰서 병원 소방서/소방서_triple.csv\", encoding='cp949')\n",
    "FOLDER_NAME = \"datasets/20220920_csv/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4f71be8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)07.csv\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)06.csv\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)02.csv\n",
      "Reading the file:  ./datasets/20220920_csv/02 해운대_배수펌프(3075794).csv\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)05.csv\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation).xlsx\n",
      "읽으려는 파일의 포멧을 확인해야함, 파일명:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation).xlsx\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)04.csv\n",
      "Reading the file:  ./datasets/20220920_csv/병원_triple.csv\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)03.csv\n",
      "Reading the file:  ./datasets/20220920_csv/00 general_triple.csv\n",
      "Reading the file:  ./datasets/20220920_csv/소방서_triple.csv\n",
      "Reading the file:  ./datasets/20220920_csv/01 부산_유수지(15054723).csv\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)01.csv\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)08.csv\n",
      "Reading the file:  ./datasets/20220920_csv/ds_r_f15048634_202111221427(relation)09.csv\n",
      "Reading the file:  ./datasets/20220920_csv/경찰서_triple.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2947622/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kg_full = kg_full.append(a_df, ignore_index=True)\n",
      "/tmp/ipykernel_2947622/4084913395.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_full = df_full.append(tmp_df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "path_to_file_folder = HOME_DIR+FOLDER_NAME\n",
    "meta_data= [\"file_name\", \"colum_name\", \"value_list\"] #the meta-data should be extented based on EDA on the datasets\n",
    "df_full = pd.DataFrame(columns=meta_data)\n",
    "meta_data= [\"head\", \"relation\", \"tail\", \"file_name\"] #the meta-data should be extented based on EDA on the datasets\n",
    "kg_full = pd.DataFrame(columns=meta_data)\n",
    "\n",
    "for file_name in [file for file in os.listdir(path_to_file_folder)]:\n",
    "    file_name = file_name\n",
    "    a_file = HOME_DIR+FOLDER_NAME+file_name\n",
    "    print(\"Reading the file: \", a_file)\n",
    "    \n",
    "    try:\n",
    "        a_df = pd.DataFrame()\n",
    "        if \".csv\" in file_name:\n",
    "            a_df = pd.read_csv(a_file, encoding='cp949', names=meta_data, header=None)\n",
    "            a_df[\"file_name\"] = file_name\n",
    "        elif \".xlsx\" in file_name:\n",
    "            a_df = pd.read_excel(a_file, names=meta_data, header=None)\n",
    "            a_df[\"file_name\"] = file_name\n",
    "        else:\n",
    "            continue\n",
    "        kg_full = kg_full.append(a_df, ignore_index=True)\n",
    "        \n",
    "\n",
    "        file_name_list = []\n",
    "        colum_name_list = []\n",
    "        value_list = []\n",
    "        for col in a_df.columns:\n",
    "            col_name = col\n",
    "            col_values = list(a_df[col_name].values)\n",
    "            file_name_list.append(file_name)\n",
    "            colum_name_list.append(col_name)\n",
    "            value_list.append(col_values)\n",
    "\n",
    "        tmp_df = pd.DataFrame({\"file_name\": file_name_list,\n",
    "                            \"colum_name\": colum_name_list,\n",
    "                            \"value_list\": value_list})\n",
    "\n",
    "        df_full = df_full.append(tmp_df, ignore_index=True)\n",
    "        \n",
    "    except:\n",
    "        print(\"읽으려는 파일의 포멧을 확인해야함, 파일명: \", a_file,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "44285896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7633</td>\n",
       "      <td>start_time</td>\n",
       "      <td>0</td>\n",
       "      <td>ds_r_f15048634_202111221427(relation)07.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7634</td>\n",
       "      <td>start_time</td>\n",
       "      <td>0</td>\n",
       "      <td>ds_r_f15048634_202111221427(relation)07.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7635</td>\n",
       "      <td>start_time</td>\n",
       "      <td>0</td>\n",
       "      <td>ds_r_f15048634_202111221427(relation)07.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7636</td>\n",
       "      <td>start_time</td>\n",
       "      <td>0</td>\n",
       "      <td>ds_r_f15048634_202111221427(relation)07.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7637</td>\n",
       "      <td>start_time</td>\n",
       "      <td>0</td>\n",
       "      <td>ds_r_f15048634_202111221427(relation)07.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10438</th>\n",
       "      <td>광남지구대</td>\n",
       "      <td>latitude</td>\n",
       "      <td>35.14537016</td>\n",
       "      <td>경찰서_triple.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10439</th>\n",
       "      <td>망미2치안센터</td>\n",
       "      <td>latitude</td>\n",
       "      <td>35.1717912</td>\n",
       "      <td>경찰서_triple.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10440</th>\n",
       "      <td>부산사상경찰서</td>\n",
       "      <td>latitude</td>\n",
       "      <td>35.17452651</td>\n",
       "      <td>경찰서_triple.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10441</th>\n",
       "      <td>부산기장경찰서</td>\n",
       "      <td>latitude</td>\n",
       "      <td>35.32481808</td>\n",
       "      <td>경찰서_triple.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10442</th>\n",
       "      <td>장안파출소</td>\n",
       "      <td>latitude</td>\n",
       "      <td>35.32478276</td>\n",
       "      <td>경찰서_triple.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10443 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          head    relation         tail  \\\n",
       "0         7633  start_time            0   \n",
       "1         7634  start_time            0   \n",
       "2         7635  start_time            0   \n",
       "3         7636  start_time            0   \n",
       "4         7637  start_time            0   \n",
       "...        ...         ...          ...   \n",
       "10438    광남지구대    latitude  35.14537016   \n",
       "10439  망미2치안센터    latitude   35.1717912   \n",
       "10440  부산사상경찰서    latitude  35.17452651   \n",
       "10441  부산기장경찰서    latitude  35.32481808   \n",
       "10442    장안파출소    latitude  35.32478276   \n",
       "\n",
       "                                         file_name  \n",
       "0      ds_r_f15048634_202111221427(relation)07.csv  \n",
       "1      ds_r_f15048634_202111221427(relation)07.csv  \n",
       "2      ds_r_f15048634_202111221427(relation)07.csv  \n",
       "3      ds_r_f15048634_202111221427(relation)07.csv  \n",
       "4      ds_r_f15048634_202111221427(relation)07.csv  \n",
       "...                                            ...  \n",
       "10438                               경찰서_triple.csv  \n",
       "10439                               경찰서_triple.csv  \n",
       "10440                               경찰서_triple.csv  \n",
       "10441                               경찰서_triple.csv  \n",
       "10442                               경찰서_triple.csv  \n",
       "\n",
       "[10443 rows x 4 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "73abe64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    kge_n_epoch = 100\n",
    "    kge_lr = 1e-4\n",
    "    kge_batch = 64\n",
    "    kge_margin = 0.5\n",
    "    kge_conv_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5e7ee74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9c0265d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kg_full[[\"head\", \"relation\", \"tail\"]].to_csv(\"triple_kb2.csv\")\n",
    "kg_full = kg_full.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e2c2e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_emb_path = './kge_save'\n",
    "os.makedirs(kb_emb_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e56ee83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchkge.utils.datasets import load_fb15k\n",
    "#kg, kg_val, kg_test = load_fb15k()\n",
    "#\n",
    "#model_convKB = ConvKBModel(256,\n",
    "#                            3,\n",
    "#                            kg.n_ent,\n",
    "#                            kg.n_rel,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "93396906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "originally counts 10443\n",
      "\n",
      "user nunique 1250, item nunique 2457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100 | mean loss: 6.70930: 100%|██████████| 100/100 [00:42<00:00,  2.34epoch/s]\n"
     ]
    }
   ],
   "source": [
    "kg, model_convKB = train_kge(kg_full[[\"head\", \"relation\", \"tail\"]],\n",
    "                             epochs=config.kge_n_epoch, \n",
    "                                lr=config.kge_lr, \n",
    "                                batch_size=config.kge_batch,\n",
    "                                margin=config.kge_margin,\n",
    "                                conv_size=config.kge_conv_size\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7fafe10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3705, 256)\n"
     ]
    }
   ],
   "source": [
    "emb_entity_ = model_convKB.get_embeddings()[0].detach().cpu().numpy()\n",
    "emb_rel_ = model_convKB.get_embeddings()[1].detach().cpu().numpy()\n",
    "\n",
    "ent_emb_dim = len(emb_entity_[0])\n",
    "ent_vocab={}\n",
    "ent_vocab['<unk>'] = 0\n",
    "ent_vocab['<pad>'] = 1\n",
    "ent_vocab.update({word: i+2 for word, i in kg.ent2ix.items()})\n",
    "ent_ids = {i: word for word, i in ent_vocab.items()}\n",
    "\n",
    "pad_emb_npa = np.zeros((1, ent_emb_dim))   #embedding for '<pad>' token.\n",
    "unk_emb_npa = np.zeros((1, ent_emb_dim))   #embedding for '<unk>' token.\n",
    "\n",
    "ent_embs_npa = np.vstack((pad_emb_npa,unk_emb_npa,emb_entity_))\n",
    "print(ent_embs_npa.shape)\n",
    "ent_emb = torch.nn.Embedding.from_pretrained(torch.from_numpy(ent_embs_npa).float(), freeze=False)\n",
    "\n",
    "with open('ent_vocab_npa.npy','wb') as f:\n",
    "    np.save(f,ent_vocab)\n",
    "\n",
    "with open('ent_embs_npa.npy','wb') as f:\n",
    "    np.save(f,ent_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0ebffeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.3021e-02,  1.9692e-02, -3.0930e-02,  3.0765e-02, -1.1452e-02,\n",
      "         -3.4523e-02,  2.2705e-02,  2.3650e-03, -5.7116e-03,  2.0812e-02,\n",
      "          7.2303e-03, -4.8079e-03, -1.4202e-02,  1.9260e-02, -4.3831e-03,\n",
      "          2.5393e-02, -1.5948e-03, -2.2197e-02,  4.4254e-04,  3.9051e-03,\n",
      "          1.4461e-02,  2.3048e-02, -2.5585e-02, -1.2434e-03,  9.9712e-03,\n",
      "          3.0517e-02,  1.0509e-02,  1.4599e-02,  3.1488e-04,  2.5773e-02,\n",
      "          3.7756e-02,  1.1176e-02, -3.1508e-03, -3.2699e-02,  3.3879e-02,\n",
      "          2.2055e-02,  2.9955e-02, -2.5195e-02,  1.1792e-02, -3.4177e-03,\n",
      "          2.8374e-02,  1.6158e-02, -3.2340e-03, -2.0495e-02,  3.7520e-02,\n",
      "          1.1076e-03,  5.5587e-03,  1.7482e-02, -2.4807e-03, -3.4690e-02,\n",
      "         -5.3119e-03,  3.1779e-02, -3.2209e-02, -1.1101e-03,  2.0448e-02,\n",
      "         -2.0217e-02,  2.2409e-03, -8.0148e-03,  1.1387e-03,  4.2913e-03,\n",
      "         -1.7926e-02,  9.6873e-03, -1.2314e-02, -3.2993e-02,  1.8669e-02,\n",
      "         -1.8284e-02, -8.2981e-03,  8.7314e-03, -2.4835e-03,  2.3248e-02,\n",
      "          9.8917e-03,  2.0044e-02,  4.5269e-04,  2.4979e-02, -1.2032e-02,\n",
      "          1.5306e-02,  2.1132e-02, -3.0809e-03, -3.8212e-02,  3.7035e-03,\n",
      "          2.0445e-02, -2.9032e-02, -2.5020e-02,  1.7558e-02,  3.1231e-02,\n",
      "         -5.2968e-03, -2.8553e-02,  9.6436e-03,  5.4319e-04, -1.0644e-02,\n",
      "          3.6809e-02,  3.7249e-02, -1.7114e-02, -1.2301e-02,  4.7809e-03,\n",
      "         -2.3167e-02,  1.0854e-02, -8.1477e-03, -2.4617e-02, -1.0021e-02,\n",
      "         -2.6111e-02,  1.0070e-02, -1.4869e-02,  1.4788e-02,  2.3186e-02,\n",
      "          1.4647e-02, -8.2488e-04, -8.4426e-04, -4.2408e-04,  2.2546e-02,\n",
      "         -2.5483e-02,  3.6501e-03, -3.1243e-02,  7.0948e-03, -9.1936e-03,\n",
      "         -2.2776e-02,  1.4638e-03, -3.4888e-02,  1.6291e-02, -4.8524e-03,\n",
      "         -1.0987e-03,  2.2285e-02,  1.5332e-02, -2.3657e-02, -2.0188e-02,\n",
      "         -3.6786e-02,  3.1512e-02,  3.6399e-03,  2.4804e-02, -4.0735e-03,\n",
      "         -1.0883e-02, -2.4042e-02,  1.5428e-02,  1.7666e-03, -5.4200e-02,\n",
      "         -2.8027e-02,  7.8692e-03,  1.9754e-02,  1.9294e-02, -3.2019e-02,\n",
      "         -1.1775e-02,  2.0122e-02, -1.7985e-02, -3.0951e-02, -3.0717e-02,\n",
      "          2.8486e-02, -5.5853e-03,  3.1660e-02, -1.9129e-02,  2.0472e-02,\n",
      "          2.3550e-02,  3.6097e-02, -2.8168e-02,  1.0129e-03,  5.3981e-03,\n",
      "          3.6456e-02,  2.0863e-04,  1.2110e-02, -1.5637e-02,  2.8347e-02,\n",
      "          7.9203e-03,  1.2427e-02,  6.7599e-03,  3.5174e-02,  3.4497e-03,\n",
      "          2.1857e-02,  1.1673e-02, -5.2571e-03,  3.6628e-02,  1.2137e-02,\n",
      "          7.4596e-03, -2.7979e-02, -2.7132e-02,  2.7621e-03,  2.1401e-02,\n",
      "          3.2017e-02, -2.0304e-03,  5.0768e-02,  2.9748e-05, -2.2128e-04,\n",
      "         -2.3842e-02,  2.0730e-03, -2.0796e-02, -1.3527e-02, -2.5117e-02,\n",
      "          2.6519e-02, -3.2221e-02,  2.8524e-02, -6.6775e-03, -1.5582e-02,\n",
      "         -9.0343e-03,  2.1318e-02,  1.4510e-03,  3.1193e-02, -1.5316e-02,\n",
      "         -8.4188e-03, -2.2528e-02, -1.5429e-02, -1.7069e-02, -1.8143e-03,\n",
      "          1.9746e-02, -3.2098e-02,  8.4073e-03, -3.3407e-02,  2.5123e-02,\n",
      "         -1.2276e-02, -1.4595e-02,  2.6750e-02, -1.8567e-02,  1.5574e-02,\n",
      "          2.8282e-02,  2.9819e-03,  3.0394e-02, -1.5831e-02,  6.9079e-03,\n",
      "          2.9041e-02, -7.6398e-03, -1.8648e-02,  7.2711e-03, -2.1569e-02,\n",
      "         -1.1112e-02,  2.4772e-02,  5.9561e-03,  3.7132e-02, -2.3096e-02,\n",
      "          5.7398e-03,  2.8689e-02, -2.3027e-02,  5.5680e-03, -2.5690e-02,\n",
      "         -1.0837e-02,  6.3444e-03,  5.8713e-03,  1.4606e-02,  1.8463e-03,\n",
      "         -2.0004e-02,  3.8442e-03,  2.4841e-02, -7.5229e-03, -2.8354e-02,\n",
      "          9.9286e-03,  1.2486e-03,  2.4919e-03,  1.7144e-02,  8.9736e-04,\n",
      "          3.3182e-02,  8.5913e-03,  1.4131e-02,  3.2636e-02,  2.0135e-02,\n",
      "         -8.0900e-03, -2.6028e-03, -2.0738e-02, -3.2668e-02, -8.6214e-03,\n",
      "          1.6839e-02],\n",
      "        [-4.4865e-02, -2.9792e-02, -3.0535e-02, -1.6027e-02, -2.2715e-02,\n",
      "         -1.1157e-04,  4.1386e-02,  6.7517e-03,  4.4838e-02, -1.7172e-02,\n",
      "         -9.2491e-03, -2.3808e-02, -1.0099e-02, -1.7311e-02, -8.4984e-03,\n",
      "         -3.6392e-02,  7.1963e-03,  1.7503e-02, -3.0298e-03,  6.9612e-04,\n",
      "          2.5101e-02,  2.0725e-02, -4.9202e-02,  4.5541e-02,  4.9978e-03,\n",
      "         -8.6168e-03, -6.9116e-03, -2.7460e-02,  4.6912e-02, -3.2161e-02,\n",
      "          1.4665e-02, -3.2900e-02, -4.1936e-03,  1.9550e-02,  2.7917e-02,\n",
      "         -8.0157e-03,  1.5676e-03,  5.8002e-03,  2.0885e-02,  9.7404e-03,\n",
      "          1.8535e-02,  7.8088e-03,  4.8239e-02,  4.5534e-02,  7.6204e-03,\n",
      "          7.0157e-03,  4.2337e-02, -6.2772e-04,  3.5331e-04,  1.8693e-02,\n",
      "          4.6946e-02,  2.7862e-02, -4.1043e-03,  4.3332e-02, -9.9113e-03,\n",
      "         -1.8547e-02,  2.5812e-02,  3.0569e-03,  3.8135e-02, -6.4866e-03,\n",
      "          1.0816e-03, -3.4991e-02, -2.8027e-02, -2.2953e-03,  4.2524e-04,\n",
      "          3.3370e-02,  1.3145e-02, -3.6726e-02,  2.5349e-02, -1.5981e-02,\n",
      "          9.7967e-03, -1.4262e-02,  3.4810e-02,  1.8501e-02,  1.6663e-03,\n",
      "         -4.1586e-02, -2.2366e-02,  6.7454e-03, -1.3516e-02,  5.4373e-03,\n",
      "         -9.9940e-03,  4.1908e-03,  2.3576e-02, -1.6313e-02,  3.8026e-02,\n",
      "          3.9992e-02, -1.4635e-02, -1.0259e-02, -2.1599e-02, -4.9466e-03,\n",
      "         -2.1139e-03, -7.1036e-03, -4.4243e-02,  5.6066e-03,  3.9161e-03,\n",
      "          1.2238e-02,  1.6578e-02, -1.0753e-02, -4.9002e-02, -1.4622e-02,\n",
      "         -3.6684e-02, -2.8871e-02,  1.9671e-02,  3.2668e-02, -2.8793e-02,\n",
      "         -7.6077e-03, -4.0162e-02,  2.0618e-02, -5.3853e-03, -2.3628e-02,\n",
      "          1.4446e-02, -1.0886e-02, -6.5078e-03,  2.5600e-02, -4.1389e-03,\n",
      "          9.6977e-03, -5.7397e-04, -4.7444e-02, -1.2750e-02, -9.6567e-03,\n",
      "          2.7871e-02, -6.2316e-03,  2.4468e-02,  1.1558e-02, -2.0585e-02,\n",
      "         -1.4252e-02, -7.0239e-03,  7.6333e-03,  3.5492e-02,  2.7732e-02,\n",
      "          2.5150e-02, -5.8508e-03, -6.1072e-03, -1.3560e-03, -6.2848e-03,\n",
      "         -2.2714e-02,  4.8908e-02, -3.7606e-02,  4.2083e-03,  8.5989e-03,\n",
      "          1.1413e-03,  1.5613e-02, -4.0675e-02, -2.5135e-02,  4.8561e-03,\n",
      "         -2.4401e-02,  1.8243e-02,  1.8528e-02,  2.7050e-03,  2.5682e-02,\n",
      "         -2.0913e-02,  2.3258e-02, -6.3867e-03,  3.9913e-03, -2.5297e-02,\n",
      "         -7.0306e-03,  3.3019e-02, -1.8564e-02, -2.6742e-02, -2.6986e-02,\n",
      "         -1.8886e-02,  4.5288e-02, -7.0300e-03,  9.5246e-04, -1.6239e-02,\n",
      "          1.5532e-02, -2.6074e-02, -8.1059e-04,  1.3550e-03,  3.5833e-02,\n",
      "         -2.7930e-02,  2.0547e-02, -1.3251e-02, -2.9022e-02,  1.1433e-03,\n",
      "          2.5685e-02, -1.3700e-02,  1.6690e-02,  3.8489e-02, -2.8042e-02,\n",
      "          7.9865e-04,  2.0753e-02,  4.6812e-02, -1.6027e-03,  6.7135e-03,\n",
      "          4.3803e-04, -4.8622e-02, -1.7039e-02,  3.6986e-02,  3.8942e-02,\n",
      "         -3.9335e-04, -1.2708e-02,  6.6565e-03, -2.4521e-02, -1.2525e-02,\n",
      "          3.8340e-03,  4.6217e-02, -1.4643e-02,  1.3504e-02, -3.6272e-02,\n",
      "         -2.4928e-03,  6.9620e-04, -3.2107e-02, -4.6476e-03, -1.7368e-02,\n",
      "          1.4309e-02, -3.3311e-03, -3.3654e-03, -3.4319e-02, -2.3214e-02,\n",
      "         -1.6743e-03,  1.5913e-02, -8.2608e-03, -1.9068e-02,  2.1328e-02,\n",
      "          4.7700e-02,  2.2254e-03, -2.5910e-02,  5.7718e-03,  1.3834e-02,\n",
      "         -1.8021e-02,  3.9393e-02, -1.5597e-02, -4.0548e-02, -3.7622e-03,\n",
      "          4.7009e-02,  2.4061e-02,  3.0799e-02, -3.3152e-02,  7.7194e-03,\n",
      "         -3.0302e-02,  8.5232e-03, -6.7174e-03, -7.8882e-03,  4.3789e-02,\n",
      "          1.5602e-02,  7.5200e-03,  4.0726e-02,  2.6041e-02,  1.6359e-02,\n",
      "         -1.3944e-03,  3.0334e-02, -2.2233e-02, -2.5237e-02, -1.8344e-02,\n",
      "          1.0437e-02, -2.9816e-02, -1.5431e-02,  8.6680e-03,  1.8639e-02,\n",
      "          1.6329e-03, -2.4735e-02, -3.8640e-04, -2.4352e-02,  2.8849e-02,\n",
      "          4.4420e-02]], grad_fn=<EmbeddingBackward>)\n",
      "tensor([[-0.0479,  0.0004, -0.0562,  0.0010, -0.0004,  0.0412,  0.0538,  0.0007,\n",
      "         -0.0016, -0.0107, -0.0379,  0.0116, -0.0563,  0.0354,  0.0161, -0.0065,\n",
      "          0.0358,  0.0433, -0.0616, -0.0500,  0.0482, -0.0043, -0.0039, -0.0022,\n",
      "         -0.0317,  0.0557, -0.0447,  0.0190,  0.0340, -0.0520, -0.0276, -0.0488,\n",
      "          0.0007, -0.0286,  0.0212, -0.0619,  0.0050, -0.0129,  0.0219,  0.0283,\n",
      "          0.0401,  0.0077,  0.0068,  0.0442, -0.0244,  0.0326,  0.0423,  0.0285,\n",
      "          0.0548,  0.0018,  0.0453,  0.0416, -0.0353,  0.0004,  0.0013,  0.0130,\n",
      "         -0.0330,  0.0330,  0.0329,  0.0502, -0.0594, -0.0279,  0.0305,  0.0012,\n",
      "         -0.0370,  0.0140, -0.0042, -0.0260,  0.0212, -0.0447, -0.0275,  0.0313,\n",
      "          0.0311,  0.0081,  0.0597, -0.0394,  0.0391, -0.0681,  0.0278, -0.0281,\n",
      "          0.0578, -0.0154, -0.0301,  0.0250,  0.0140,  0.0112,  0.0224,  0.0390,\n",
      "         -0.0063,  0.0345, -0.0435, -0.0260, -0.0329,  0.0308,  0.0364, -0.0517,\n",
      "          0.0410, -0.0118, -0.0159, -0.0252, -0.0191, -0.0306,  0.0319, -0.0050,\n",
      "         -0.0266, -0.0158, -0.0470, -0.0263,  0.0143,  0.0016, -0.0004,  0.0040,\n",
      "         -0.0551, -0.0340, -0.0419,  0.0487,  0.0348, -0.0290,  0.0183, -0.0346,\n",
      "          0.0030, -0.0341,  0.0078,  0.0316,  0.0442,  0.0542, -0.0176,  0.0268,\n",
      "          0.0519,  0.0176,  0.0406, -0.0210, -0.0020,  0.0353,  0.0139,  0.0403,\n",
      "          0.0336, -0.0227,  0.0482, -0.0504,  0.0320,  0.0302,  0.0056, -0.0061,\n",
      "          0.0339, -0.0577,  0.0265,  0.0417,  0.0315, -0.0458,  0.0294,  0.0166,\n",
      "          0.0199,  0.0255, -0.0500,  0.0052,  0.0205, -0.0198, -0.0193, -0.0214,\n",
      "         -0.0645,  0.0275,  0.0486, -0.0074, -0.0010,  0.0050,  0.0041,  0.0576,\n",
      "         -0.0030,  0.0155,  0.0295,  0.0146,  0.0257, -0.0214, -0.0433, -0.0055,\n",
      "          0.0368, -0.0614,  0.0019, -0.0574,  0.0309, -0.0512,  0.0288,  0.0221,\n",
      "         -0.0018,  0.0567, -0.0439,  0.0538,  0.0048,  0.0004, -0.0163, -0.0060,\n",
      "          0.0433,  0.0381,  0.0578,  0.0454,  0.0188,  0.0366,  0.0062, -0.0288,\n",
      "          0.0024, -0.0221, -0.0086,  0.0072,  0.0635, -0.0372,  0.0221,  0.0316,\n",
      "         -0.0582,  0.0338, -0.0066,  0.0090, -0.0043,  0.0461, -0.0003,  0.0462,\n",
      "         -0.0387,  0.0379, -0.0241,  0.0244, -0.0542,  0.0319,  0.0198, -0.0216,\n",
      "          0.0293,  0.0376,  0.0281,  0.0243,  0.0463,  0.0371, -0.0071, -0.0216,\n",
      "          0.0406,  0.0070,  0.0506,  0.0280,  0.0662,  0.0649, -0.0202, -0.0067,\n",
      "         -0.0200,  0.0083, -0.0051,  0.0345, -0.0329, -0.0371, -0.0256, -0.0343,\n",
      "         -0.0182, -0.0252, -0.0252, -0.0503, -0.0049, -0.0334,  0.0592,  0.0496]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(ent_emb(torch.LongTensor([10, 15]))) \n",
    "ids = ent_vocab[\"부곡지구대\"]\n",
    "print(ent_emb(torch.LongTensor([ids])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "58a184b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3018, 2095, 2653, 2610, 2030, 2606, 1830, 1829, 1827, 2404, 2084, 2209,\n",
       "        1828, 2162, 2609, 2205, 2557, 2258, 2608, 2446, 2549, 2680, 2612, 2633,\n",
       "        2409, 2651, 1970, 1968, 2093, 2161, 2054, 2148, 2164, 2089, 2466, 2727,\n",
       "        1852, 2163, 2585, 2157, 2765, 1804, 2701, 1811, 1861, 2572, 2450, 2693,\n",
       "        2671, 1755, 2220, 2451, 1996, 2670, 2017, 2168, 2605, 1851, 2170, 2648,\n",
       "        2223, 2212, 2582, 1781, 2576, 2340, 2599, 3382, 2624, 2564, 2638, 2137,\n",
       "        2616, 2471, 2602, 2696, 2678, 2677, 2219, 2719, 1767, 2166, 2232, 2580,\n",
       "        1786, 2072, 2590, 2376, 1826, 2706, 2573, 2560, 3162, 1799, 2611, 2214,\n",
       "        2548, 2584, 2712, 2150])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_name=\"부곡지구대\"\n",
    "e1_ids = ent_vocab[ent_name]\n",
    "e1_torch = ent_emb(torch.LongTensor([e1_ids]))\n",
    "e2_ids = np.arange(0, len(ent_vocab))\n",
    "e2_torch = ent_emb(torch.LongTensor([e2_ids])).squeeze()\n",
    "similarity = cosine_similarity(e1_torch, e2_torch)\n",
    "s_value, s_ids = torch.topk(similarity, 100)\n",
    "s_ids = s_ids.squeeze()\n",
    "s_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "95718627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3018)\n",
      "부곡지구대\n",
      "tensor(2095)\n",
      "7991\n",
      "tensor(2653)\n",
      "8511\n",
      "tensor(2610)\n",
      "8469\n",
      "tensor(2030)\n",
      "7926\n",
      "tensor(2606)\n",
      "8465\n",
      "tensor(1830)\n",
      "7731\n",
      "tensor(1829)\n",
      "7730\n",
      "tensor(1827)\n",
      "7728\n",
      "tensor(2404)\n",
      "8271\n",
      "tensor(2084)\n",
      "7980\n",
      "tensor(2209)\n",
      "8083\n",
      "tensor(1828)\n",
      "7729\n",
      "tensor(2162)\n",
      "8036\n",
      "tensor(2609)\n",
      "8468\n",
      "tensor(2205)\n",
      "8079\n",
      "tensor(2557)\n",
      "8416\n",
      "tensor(2258)\n",
      "8128\n",
      "tensor(2608)\n",
      "8467\n",
      "tensor(2446)\n",
      "8309\n",
      "tensor(2549)\n",
      "8408\n",
      "tensor(2680)\n",
      "8538\n",
      "tensor(2612)\n",
      "8471\n",
      "tensor(2633)\n",
      "8492\n",
      "tensor(2409)\n",
      "8276\n",
      "tensor(2651)\n",
      "8509\n",
      "tensor(1970)\n",
      "7868\n",
      "tensor(1968)\n",
      "7866\n",
      "tensor(2093)\n",
      "7989\n",
      "tensor(2161)\n",
      "8035\n",
      "tensor(2054)\n",
      "7950\n",
      "tensor(2148)\n",
      "8022\n",
      "tensor(2164)\n",
      "8038\n",
      "tensor(2089)\n",
      "7985\n",
      "tensor(2466)\n",
      "8329\n",
      "tensor(2727)\n",
      "8585\n",
      "tensor(1852)\n",
      "7753\n",
      "tensor(2163)\n",
      "8037\n",
      "tensor(2585)\n",
      "8444\n",
      "tensor(2157)\n",
      "8031\n",
      "tensor(2765)\n",
      "8623\n",
      "tensor(1804)\n",
      "7705\n",
      "tensor(2701)\n",
      "8559\n",
      "tensor(1811)\n",
      "7712\n",
      "tensor(1861)\n",
      "7762\n",
      "tensor(2572)\n",
      "8431\n",
      "tensor(2450)\n",
      "8313\n",
      "tensor(2693)\n",
      "8551\n",
      "tensor(2671)\n",
      "8529\n",
      "tensor(1755)\n",
      "7659\n",
      "tensor(2220)\n",
      "8094\n",
      "tensor(2451)\n",
      "8314\n",
      "tensor(1996)\n",
      "7894\n",
      "tensor(2670)\n",
      "8528\n",
      "tensor(2017)\n",
      "7913\n",
      "tensor(2168)\n",
      "8042\n",
      "tensor(2605)\n",
      "8464\n",
      "tensor(1851)\n",
      "7752\n",
      "tensor(2170)\n",
      "8044\n",
      "tensor(2648)\n",
      "8506\n",
      "tensor(2223)\n",
      "8097\n",
      "tensor(2212)\n",
      "8086\n",
      "tensor(2582)\n",
      "8441\n",
      "tensor(1781)\n",
      "7685\n",
      "tensor(2576)\n",
      "8435\n",
      "tensor(2340)\n",
      "8207\n",
      "tensor(2599)\n",
      "8458\n",
      "tensor(3382)\n",
      "재송2\n",
      "tensor(2624)\n",
      "8483\n",
      "tensor(2564)\n",
      "8423\n",
      "tensor(2638)\n",
      "8497\n",
      "tensor(2137)\n",
      "8011\n",
      "tensor(2616)\n",
      "8475\n",
      "tensor(2471)\n",
      "8334\n",
      "tensor(2602)\n",
      "8461\n",
      "tensor(2696)\n",
      "8554\n",
      "tensor(2678)\n",
      "8536\n",
      "tensor(2677)\n",
      "8535\n",
      "tensor(2219)\n",
      "8093\n",
      "tensor(2719)\n",
      "8577\n",
      "tensor(1767)\n",
      "7671\n",
      "tensor(2166)\n",
      "8040\n",
      "tensor(2232)\n",
      "8102\n",
      "tensor(2580)\n",
      "8439\n",
      "tensor(1786)\n",
      "7690\n",
      "tensor(2072)\n",
      "7968\n",
      "tensor(2590)\n",
      "8449\n",
      "tensor(2376)\n",
      "8243\n",
      "tensor(1826)\n",
      "7727\n",
      "tensor(2706)\n",
      "8564\n",
      "tensor(2573)\n",
      "8432\n",
      "tensor(2560)\n",
      "8419\n",
      "tensor(3162)\n",
      "부산서부경찰서\n",
      "tensor(1799)\n",
      "7700\n",
      "tensor(2611)\n",
      "8470\n",
      "tensor(2214)\n",
      "8088\n",
      "tensor(2548)\n",
      "8407\n",
      "tensor(2584)\n",
      "8443\n",
      "tensor(2712)\n",
      "8570\n",
      "tensor(2150)\n",
      "8024\n"
     ]
    }
   ],
   "source": [
    "for idx in s_ids:\n",
    "    print(idx)\n",
    "    print(ent_ids[int(idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "582e86af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_example_on_TransE(kg, ent_name=\"부곡지구대\"):\n",
    "    e1 = emb_entity_[kg.ent2ix[ent_name]]\n",
    "    r1 = emb_entity_[kg.rel2ix['koad:roadNameCode']]\n",
    "    e2 = emb_entity_[kg.head_idx]\n",
    "    similarity = cosine_similarity(torch.Tensor([e1]), torch.Tensor(e2))\n",
    "    s_value, s_ids = torch.topk(similarity, 10)\n",
    "    for idx in s_ids:\n",
    "        print(int(idx))\n",
    "        print(kg.head_idx[int(idx)])\n",
    "        print(kg.ix2ent[int(kg.head_idx[int(idx)])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78d1e6b",
   "metadata": {},
   "source": [
    "## text to KB entity module\n",
    " - input: text (entity name)\n",
    " - output: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d5c67cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDiveEmb(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, out_dim):\n",
    "        super(KLDiveEmb, self).__init__()\n",
    "\n",
    "        self.bert = transformers.XLMRobertaModel.from_pretrained('xlm-roberta-base')\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.drop_out = nn.Dropout(0.33)\n",
    "        self.fc1 = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, idx, mask):\n",
    "    \n",
    "        x = self.bert(idx, mask) \n",
    "        x = x.pooler_output\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.drop_out(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        return F.softmax(x, dim=1), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "80e38e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLEDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenizer, data, max_token):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token = max_token \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        e_name = self.data['e_name'][index] #Entity Name\n",
    "        e_emb = self.data['e_emb'][index]  #KB embedding\n",
    "            \n",
    "        tokenized = self.tokenizer.encode_plus(\"\".join(e_name),\n",
    "                                                None,\n",
    "                                                add_special_tokens=True,\n",
    "                                                max_length = self.max_token,\n",
    "                                                padding='max_length',\n",
    "                                                truncation=True,\n",
    "                                              )\n",
    "        \n",
    "        ids = tokenized['input_ids']\n",
    "        mask = tokenized['attention_mask']\n",
    "\n",
    "        return {'e_ids': torch.tensor(ids, dtype=torch.long), \n",
    "                'e_mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'target': torch.tensor(e_emb)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b4a33ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = KLDiveEmb(768, 512, 256).to(DEVICE)\n",
    "criterion = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005)\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1e5d6e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "k,i,v = [],[],[]\n",
    "for ent, idx in ent_vocab.items():\n",
    "    ent_name=ent\n",
    "    e1_ids = ent_vocab[ent_name]\n",
    "    e1_torch = ent_emb(torch.LongTensor([e1_ids]))\n",
    "    k.append(ent)\n",
    "    i.append(idx)\n",
    "    v.append(e1_torch.squeeze().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "07306a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['e_name','e_idx', 'e_emb'])\n",
    "df[\"e_name\"] = k\n",
    "df[\"e_idx\"] = i\n",
    "df[\"e_emb\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4a1236d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(df, test_size=0.2)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "89df0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KLEDataset(tokenizer, train_df, max_token=20)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=4, shuffle=True, pin_memory=True)\n",
    "valid_dataset = KLEDataset(tokenizer, valid_df, max_token=20) \n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size , num_workers=4, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "55d531ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    batch_loss = []\n",
    "    for idx, batch in tqdm(enumerate(train_loader), total=len(train_loader), leave=False): #학습 데이터를 batch size만큼씩 읽어옴\n",
    "        optimizer.zero_grad()\n",
    "        e_ids = batch['e_ids'].to(DEVICE) #entity_name\n",
    "        e_bert_mask = batch['e_mask'].to(DEVICE) \n",
    "        \n",
    "        logits, _ = model(e_ids, e_bert_mask) \n",
    "                \n",
    "        target = batch['target'].to(DEVICE) #KB embedding\n",
    "        target = F.softmax(target, dim=1)\n",
    "        target.requires_grad = False\n",
    "        loss = criterion(logits.log(), target)\n",
    "\n",
    "        batch_loss.append(float(loss.item()))\n",
    "        loss.backward(loss)\n",
    "        optimizer.step()\n",
    "        \n",
    "    return sum(batch_loss) / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9c97426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fn(model, valid_loader, criterion):\n",
    "    model.eval()\n",
    "    batch_loss = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in tqdm(enumerate(valid_loader), total=len(valid_loader), leave=False): #학습 데이터를 batch size만큼씩 읽어옴\n",
    "            optimizer.zero_grad()\n",
    "            e_ids = batch['e_ids'].to(DEVICE) #entity_name\n",
    "            e_bert_mask = batch['e_mask'].to(DEVICE) \n",
    "            \n",
    "            logits, _ = model(e_ids, e_bert_mask) \n",
    "                    \n",
    "            target = batch['target'].to(DEVICE) #KB embedding\n",
    "            target = F.softmax(target, dim=1)\n",
    "            loss = criterion(logits.log(), target)\n",
    "\n",
    "            batch_loss.append(float(loss.item()))\n",
    "        \n",
    "    return sum(batch_loss) / len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1084ae79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010539988152425182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006732494827914746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006405220111891469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006218416556874488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006122241017131254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_epoch_loss = []\n",
    "test_epoch_loss = []\n",
    "for epoch in range(5):\n",
    "    train_avg_loss = train_fn(model, train_loader, optimizer, criterion)\n",
    "    train_epoch_loss.append(train_avg_loss)\n",
    "    print(train_avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "977ecb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005474132534194117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "valid_avg_loss = valid_fn(model, valid_loader, criterion)\n",
    "print(valid_avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5abddef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, keyword=\"춘천\"):\n",
    "\n",
    "    e_name = keyword\n",
    "    tokenized = tokenizer.encode_plus(\"\".join(e_name),\n",
    "                                        None,\n",
    "                                        add_special_tokens=True,\n",
    "                                        max_length = 20,\n",
    "                                        padding='max_length',\n",
    "                                        truncation=True,\n",
    "                                        )\n",
    "\n",
    "    ids = tokenized['input_ids']\n",
    "    mask = tokenized['attention_mask']\n",
    "\n",
    "    batch = {'e_ids': torch.tensor(ids, dtype=torch.long), \n",
    "             'e_mask': torch.tensor(mask, dtype=torch.long)}\n",
    "\n",
    "    e_ids = batch['e_ids'].to(DEVICE).unsqueeze(0) #entity_name\n",
    "    e_bert_mask = batch['e_mask'].to(DEVICE).unsqueeze(0) \n",
    "    logits, word_emb = model(e_ids, e_bert_mask)\n",
    "    e1_torch = word_emb.cpu()\n",
    "    e2_ids = np.arange(0, len(ent_vocab))\n",
    "    e2_torch = ent_emb(torch.LongTensor([e2_ids])).squeeze()\n",
    "    similarity = cosine_similarity(e1_torch, e2_torch)\n",
    "    s_value, s_ids = torch.topk(similarity, 10)\n",
    "    s_ids = s_ids.squeeze()\n",
    "    s_ids\n",
    "\n",
    "    return s_ids.detach().numpy(), s_value.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e226f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_ex_matching(df, query = \"<unk>\"):\n",
    "    keyword = query\n",
    "    exist_boolean = (df[\"e_name\"] == keyword).any()\n",
    "    ex_matching = 0 #기본적으로 \"<unk>\"로 해둠\n",
    "    if exist_boolean: \n",
    "        ex_matching = int(df[df[\"e_name\"] == keyword]['e_idx']) \n",
    "    else: \n",
    "        ex_matching = 0\n",
    "\n",
    "    return ex_matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "65f3defd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3018, '부곡지구대']]\n",
      "[[1836, '7737']]\n",
      "[[2133, '8007']]\n",
      "[[1788, '7692']]\n",
      "[[2629, '8488']]\n",
      "[[1871, '7772']]\n",
      "[[1828, '7729']]\n",
      "[[2163, '8037']]\n",
      "[[2094, '7990']]\n",
      "[[2671, '8529']]\n",
      "[[2752, '8610']]\n"
     ]
    }
   ],
   "source": [
    "query = \"부곡지구대\"\n",
    "ex_ids = search_ex_matching(df, query)\n",
    "s_ids, s_score = prediction(model, query)\n",
    "total_ids = np.concatenate([np.array([ex_ids]), s_ids]) \n",
    "\n",
    "for idx in total_ids:\n",
    "    print(df[df['e_idx'] == int(idx)][[\"e_idx\",\"e_name\"]].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bef9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145a934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
